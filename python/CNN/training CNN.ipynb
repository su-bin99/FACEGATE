{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "#전역변수\n",
    "image_size = 256\n",
    "image_color = 3\n",
    "maxpool_filter_size = 2\n",
    "num_classes = 6 #분류하는 사람 수\n",
    "#batch_size = 100\n",
    "learning_rate = 0.0001\n",
    "\n",
    "\n",
    "#filter\n",
    "#conv1 - 3*3*3 필터 16개, image size 256\n",
    "#conv2 - 3*3*16 필터 32개, image size 128\n",
    "#conv3 - 3*3*32 필터 64개, image size 64\n",
    "#conv4 - 5*5*64 필터 128개, image size 32\n",
    "#max pooling - 모두 2*2로 stride 2씩. maxpooling stride가 2 stride라 이미지 size 반 씩 줄어듬\n",
    "\n",
    "#학습 정도에 따라 필터 개수나 사이즈를 조정해주세요\n",
    "\n",
    "\n",
    "\n",
    "#convolutional network layer 1\n",
    "def conv1(input_data):\n",
    "    #layer 1 설정값(convolutional layer)\n",
    "    conv1_filter_size = 3\n",
    "    conv1_layer_size = 16\n",
    "    stride1 = 1\n",
    "    \n",
    "    with tf.name_scope('conv1'):\n",
    "        #filter define\n",
    "        W_conv1 = tf.Variable(tf.truncated_normal([conv1_filter_size,\n",
    "                                                   conv1_filter_size,\n",
    "                                                   image_color,\n",
    "                                                   conv1_layer_size],\n",
    "                                                   stddev=0.1))\n",
    "        #bias\n",
    "        b1 = tf.Variable(tf.truncated_normal([conv1_layer_size],stddev=0.1))\n",
    "       \n",
    "        #filter apply\n",
    "        #convolutional network define\n",
    "        h_conv1 = tf.nn.conv2d(input_data,W_conv1,strides=[1,1,1,1],padding='SAME')\n",
    "        #활성함수(Activation function)\n",
    "        h_conv1_relu = tf.nn.relu(tf.add(h_conv1,b1))\n",
    "        #Max Pooling\n",
    "        h_conv1_maxpool = tf.nn.max_pool(h_conv1_relu,\n",
    "                                        ksize=[1,2,2,1],\n",
    "                                        strides = [1,2,2,1],\n",
    "                                        padding='SAME')\n",
    "    \n",
    "    return h_conv1_maxpool\n",
    "\n",
    "#convolutional network layer2\n",
    "def conv2(input_data):\n",
    "    #layer 2 설정값\n",
    "    conv2_filter_size = 3\n",
    "    conv2_layer_size = 32\n",
    "    conv1_layer_size = 16\n",
    "    stride2 = 1\n",
    "    \n",
    "    with tf.name_scope('conv_2'):\n",
    "        #filter define\n",
    "        W_conv2 = tf.Variable(tf.truncated_normal([conv2_filter_size,\n",
    "                                                   conv2_filter_size,\n",
    "                                                   conv1_layer_size,\n",
    "                                                   conv2_layer_size],\n",
    "                                                   stddev=0.1))\n",
    "        #bias\n",
    "        b2 = tf.Variable(tf.truncated_normal([conv2_layer_size],\n",
    "                                             stddev=0.1))\n",
    "       \n",
    "        #filter apply\n",
    "        #convolutional network define\n",
    "        h_conv2 = tf.nn.conv2d(input_data,W_conv2,strides=[1,1,1,1],padding='SAME')\n",
    "        #활성함수(Activation function)\n",
    "        h_conv2_relu = tf.nn.relu(tf.add(h_conv2,b2))\n",
    "        #Max Pooling\n",
    "        h_conv2_maxpool = tf.nn.max_pool(h_conv2_relu,\n",
    "                                        ksize=[1,2,2,1],\n",
    "                                        strides = [1,2,2,1],\n",
    "                                        padding='SAME')\n",
    "    \n",
    "    return h_conv2_maxpool\n",
    "\n",
    "\n",
    "#convolutional network layer3\n",
    "def conv3(input_data):\n",
    "    conv3_filter_size = 3\n",
    "    conv3_layer_size = 64\n",
    "    conv2_layer_size = 32\n",
    "    stride3 = 1\n",
    "    \n",
    "    with tf.name_scope('conv_3'):\n",
    "        #filter define\n",
    "        W_conv3 = tf.Variable(tf.truncated_normal([conv3_filter_size,\n",
    "                                                   conv3_filter_size,\n",
    "                                                   conv2_layer_size,\n",
    "                                                   conv3_layer_size],\n",
    "                                                   stddev=0.1))\n",
    "        #bias\n",
    "        b3 = tf.Variable(tf.truncated_normal([conv3_layer_size],\n",
    "                                             stddev=0.1))\n",
    "       \n",
    "        #filter apply\n",
    "        #convolutional network define\n",
    "        h_conv3 = tf.nn.conv2d(input_data,W_conv3,strides=[1,1,1,1],padding='SAME')\n",
    "        #활성함수(Activation function)\n",
    "        h_conv3_relu = tf.nn.relu(tf.add(h_conv3,b3))\n",
    "        #Max Pooling\n",
    "        h_conv3_maxpool = tf.nn.max_pool(h_conv3_relu,\n",
    "                                        ksize=[1,2,2,1],\n",
    "                                        strides = [1,2,2,1],\n",
    "                                        padding='SAME')\n",
    "    \n",
    "    return h_conv3_maxpool\n",
    "\n",
    "#convolutional network layer 4\n",
    "def conv4(input_data):\n",
    "    conv4_filter_size = 5\n",
    "    conv4_layer_size = 128\n",
    "    conv3_layer_size = 64\n",
    "    stride4 = 1\n",
    "    \n",
    "    with tf.name_scope('conv_4'):\n",
    "        W_conv4 = tf.Variable(tf.truncated_normal([conv4_filter_size,\n",
    "                                                   conv4_filter_size,\n",
    "                                                   conv3_layer_size,\n",
    "                                                   conv4_layer_size],\n",
    "                                              stddev=0.1))\n",
    "        b4 = tf.Variable(tf.truncated_normal([conv4_layer_size],\n",
    "                                             stddev=0.1))\n",
    "        h_conv4 = tf.nn.conv2d(input_data,W_conv4,strides=[1,1,1,1],padding='SAME')\n",
    "        h_conv4_relu = tf.nn.relu(tf.add(h_conv4,b4))\n",
    "        h_conv4_maxpool = tf.nn.max_pool(h_conv4_relu\n",
    "                                        ,ksize=[1,2,2,1]\n",
    "                                        ,strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "        \n",
    "    return h_conv4_maxpool\n",
    "\n",
    "#fully connected layer 1\n",
    "def fc1(input_data):\n",
    "    #128 = conv4 layer size\n",
    "    input_layer_size = 16*16*128\n",
    "    fc1_layer_size = 512\n",
    "    \n",
    "    with tf.name_scope('fc_1'):\n",
    "        #앞에서 입력받은 다차원 텐서를 FCC에 넣기 위해 1차원으로 변환\n",
    "        input_data_reshape = tf.reshape(input_data,[-1,input_layer_size])\n",
    "        W_fc1 = tf.Variable(tf.truncated_normal([input_layer_size,fc1_layer_size],stddev=0.1))\n",
    "        b_fc1 = tf.Variable(tf.truncated_normal(\n",
    "                        [fc1_layer_size],stddev=0.1))\n",
    "        h_fc1 = tf.add(tf.matmul(input_data_reshape,W_fc1) , b_fc1) \n",
    "        \n",
    "        # h_fc1 = input_data*W_fc1 + b_fc1\n",
    "        h_fc1_relu = tf.nn.relu(h_fc1)\n",
    "        \n",
    "    return h_fc1_relu\n",
    "\n",
    "#fully connected layer 2\n",
    "def fc2(input_data):\n",
    "    fc1_layer_size = 512\n",
    "    fc2_layer_size = 256\n",
    "    \n",
    "    with tf.name_scope('fc_2'):\n",
    "        W_fc2 = tf.Variable(tf.truncated_normal([fc1_layer_size,fc2_layer_size],stddev=0.1))\n",
    "        b_fc2 = tf.Variable(tf.truncated_normal(\n",
    "                        [fc2_layer_size],stddev=0.1))\n",
    "        h_fc2 = tf.add(tf.matmul(input_data,W_fc2) , b_fc2) # h_fc1 = input_data*W_fc1 + b_fc1\n",
    "        h_fc2_relu = tf.nn.relu(h_fc2)\n",
    "    \n",
    "    return h_fc2_relu\n",
    "\n",
    "#final layer\n",
    "# 최종 레이어에 softmax 함수는 적용하지 않았다. \n",
    "# 카테고리(인물)에 대한 확률로 결과를 낸다\n",
    "def final_out(input_data):\n",
    "    \n",
    "    with tf.name_scope('final_out'):\n",
    "        W_fo = tf.Variable(tf.truncated_normal([256,num_classes],stddev=0.1))\n",
    "        b_fo = tf.Variable(tf.truncated_normal(\n",
    "                        [num_classes],stddev=0.1))\n",
    "        h_fo = tf.add(tf.matmul(input_data,W_fo) , b_fo) # h_fc1 = input_data*W_fc1 + b_fc1\n",
    "        \n",
    "    return h_fo\n",
    "\n",
    "#전체 네트워크 모델 정의\n",
    "#계층을 묶는다\n",
    "def build_model(images,keep_prob):\n",
    "    # define CNN network graph\n",
    "    # output shape will be (*,48,48,16)\n",
    "    r_cnn1 = conv1(images) # convolutional layer 1\n",
    "    print (\"shape after cnn1 \",r_cnn1.get_shape())\n",
    "    \n",
    "    # output shape will be (*,24,24,32)\n",
    "    r_cnn2 = conv2(r_cnn1) # convolutional layer 2\n",
    "    print (\"shape after cnn2 :\",r_cnn2.get_shape() )\n",
    "    \n",
    "    # output shape will be (*,12,12,64)\n",
    "    r_cnn3 = conv3(r_cnn2) # convolutional layer 3\n",
    "    print (\"shape after cnn3 :\",r_cnn3.get_shape() )\n",
    "\n",
    "    # output shape will be (*,6,6,128)\n",
    "    r_cnn4 = conv4(r_cnn3) # convolutional layer 4\n",
    "    print (\"shape after cnn4 :\",r_cnn4.get_shape() )\n",
    "    \n",
    "    # fully connected layer 1\n",
    "    r_fc1 = fc1(r_cnn4)\n",
    "    print (\"shape after fc1 :\",r_fc1.get_shape() )\n",
    "\n",
    "    # fully connected layer2\n",
    "    r_fc2 = fc2(r_fc1)\n",
    "    print (\"shape after fc2 :\",r_fc2.get_shape() )\n",
    "    \n",
    "    # drop out\n",
    "    # 트레이닝시에는 keep_prob < 1.0 , Test 시에는 1.0으로 한다. \n",
    "    r_dropout = tf.nn.dropout(r_fc2,keep_prob)\n",
    "    print (\"shape after dropout :\",r_dropout.get_shape() ) \n",
    "    \n",
    "    # final layer\n",
    "    r_out = final_out(r_dropout)\n",
    "    print (\"shape after final layer :\",r_out.get_shape() )\n",
    "\n",
    " \n",
    "    return r_out \n",
    "\n",
    "\n",
    "#학습 부분. 임의 작성이기 때문에 수정해서 사용해주세요\n",
    "#모델이 동작하는지만 확인한 코드입니다\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #경로 수정해서 사용\n",
    "    #X : image\n",
    "    #Y : label\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test = np.load(\"C:/Users/his78/Downloads/facedata_test_final1.npy\",allow_pickle=True)\n",
    "    \n",
    "X_train.shape\n",
    "X_test.shape\n",
    "Y_train.shape\n",
    "Y_test.shape\n",
    "print(\"x train shape : \", X_train.shape)\n",
    "print(\"x test shape : \", X_test.shape)\n",
    "print(\"y train shape : \", Y_train.shape)\n",
    "print(\"y test shape : \", Y_test.shape)\n",
    "    \n",
    "X_train =  X_train.astype('float32')/255\n",
    "X_test =  X_test.astype('float32')/255\n",
    "\n",
    "    \n",
    "\n",
    "images = tf.placeholder(tf.float32,[None,image_size,image_size,image_color])\n",
    "labels = tf.placeholder(tf.float32,[None,num_classes])\n",
    "    \n",
    "    # dropout ratio\n",
    "keep_prob = tf.placeholder(tf.float32) \n",
    "    #CNN에 image랑 dropout ratio 넘김\n",
    "prediction = build_model(images,keep_prob)\n",
    "\n",
    "    #정확도 측정 위해\n",
    "hypothesis = tf.nn.softmax(prediction)\n",
    "\n",
    "    \n",
    "    #cross entropy 손실함수로 정의\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=labels))\n",
    "\n",
    "    #define Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    batch_size = 10\n",
    "\n",
    "    for epoch in range(1,50):\n",
    "\n",
    "        avg_cost = 0\n",
    "      \n",
    "        for i in range(int(np.ceil(len(X_train)/batch_size))):\n",
    "            \n",
    "            x_ = X_train[batch_size*i : batch_size*(i+1)]\n",
    "            y_ = Y_train[batch_size*i : batch_size*(i+1)]\n",
    "\n",
    "            _,cost_val = sess.run([optimizer,loss],\n",
    "                                   feed_dict={images:x_,labels:y_,keep_prob:0.7})\n",
    "\n",
    "            avg_cost += cost_val     \n",
    "            \n",
    "        if( epoch %10 == 0):\n",
    "                \n",
    "            print(\"Epoch:\", '%04d' % (epoch), \"cost=\", \"{:.9f}\".format(avg_cost/len(X_train)))\n",
    "                \n",
    "    save_path = saver.save(sess,\"C:/Users/his78/Face_Recognition/data/model.ckpt\")\n",
    "    print(\"Model saved in file:\",save_path)\n",
    "\n",
    "    \n",
    "    is_correct = tf.equal(tf.argmax(hypothesis,1),tf.argmax(labels,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    "    print(\"정확도 : \",sess.run(accuracy,feed_dict={images:X_test,labels:Y_test,keep_prob:1.0}))\n",
    "    \n",
    "    print('finish')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
